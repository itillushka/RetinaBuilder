{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y-axis (Depth) Alignment - 2D Phase Correlation Method\n",
    "\n",
    "## Problem with previous 1D correlation approach:\n",
    "- Averaged profile along X-axis: `ref_profile = ref_norm.mean(axis=1)`\n",
    "- **Lost spatial information** about vessel structure\n",
    "- Result: 53% confidence but only 0.1% improvement\n",
    "- High variance in offsets (std=41.87 px)\n",
    "\n",
    "## New approach: 2D Phase Correlation (inspired by Phase 3 success)\n",
    "- Use **full 2D B-scan images** (not averaged profiles)\n",
    "- Apply **phase correlation** like in X-Z alignment (which worked great!)\n",
    "- Preserves spatial structure of vessels and retinal layers\n",
    "- Find Y-offset for each B-scan individually\n",
    "\n",
    "## Expected improvement:\n",
    "- X-Z alignment: 15.8% improvement with 2D phase correlation ‚úÖ\n",
    "- Y alignment: Currently 0.1% with 1D correlation ‚ùå\n",
    "- Goal: >5% improvement with 2D phase correlation üéØ\n",
    "\n",
    "## Pipeline:\n",
    "1. Load volumes and X-Z registration results\n",
    "2. Implement 2D phase correlation for Y-offset\n",
    "3. Test on 10 sample B-scans\n",
    "4. Compare with current 1D method\n",
    "5. If successful: apply to all 360 B-scans\n",
    "6. Visualize and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import ndimage, signal\n",
    "from scipy.fft import fft2, ifft2, fftshift\n",
    "import time\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from oct_volumetric_viewer import OCTImageProcessor, OCTVolumeLoader\n",
    "\n",
    "# Setup paths\n",
    "notebook_dir = Path.cwd()\n",
    "if notebook_dir.name == 'notebooks':\n",
    "    data_dir = notebook_dir / 'data'\n",
    "    oct_data_dir = notebook_dir.parent / 'oct_data'\n",
    "else:\n",
    "    data_dir = notebook_dir / 'notebooks' / 'data'\n",
    "    oct_data_dir = notebook_dir / 'oct_data'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"‚úì Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load X-Z Registration Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X-Z registration parameters from Phase 3\n",
    "xy_params = np.load(data_dir / 'xy_registration_params.npy', allow_pickle=True).item()\n",
    "\n",
    "print(\"üìä X-Z Registration Parameters (from Phase 3):\")\n",
    "print(f\"  Method: {xy_params.get('best_method', 'phase_correlation')}\")\n",
    "print(f\"  X offset (lateral): {xy_params['offset_x']} pixels\")\n",
    "print(f\"  Z offset (B-scan): {xy_params['offset_z']} pixels\")\n",
    "print(f\"  Confidence: {xy_params['confidence']:.2f}\")\n",
    "print(f\"  Improvement: {xy_params['improvement_percent']:.1f}%\")\n",
    "print(f\"\\nüí° 2D phase correlation worked great for X-Z! Let's use it for Y too.\")\n",
    "\n",
    "offset_x = xy_params['offset_x']\n",
    "offset_z = xy_params['offset_z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Full 3D Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading full 3D OCT volumes...\")\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "# Initialize loader\n",
    "processor = OCTImageProcessor(sidebar_width=250, crop_top=100, crop_bottom=50)\n",
    "loader = OCTVolumeLoader(processor)\n",
    "\n",
    "# Find F001 volumes\n",
    "bmp_dirs = []\n",
    "for bmp_file in oct_data_dir.rglob('*.bmp'):\n",
    "    vol_dir = bmp_file.parent\n",
    "    if vol_dir not in bmp_dirs:\n",
    "        bmp_dirs.append(vol_dir)\n",
    "\n",
    "all_volume_dirs = sorted(bmp_dirs)\n",
    "f001_vols = [v for v in all_volume_dirs if 'F001_IP' in str(v)]\n",
    "\n",
    "if len(f001_vols) >= 2:\n",
    "    print(f\"\\nUsing F001 data:\")\n",
    "    print(f\"  Volume 0: {f001_vols[0].name}\")\n",
    "    print(f\"  Volume 1: {f001_vols[1].name}\")\n",
    "    volume_dirs = f001_vols[:2]\n",
    "else:\n",
    "    print(f\"\\nWarning: Using first 2 available volumes\")\n",
    "    volume_dirs = all_volume_dirs[:2]\n",
    "\n",
    "# Load volumes\n",
    "print(\"\\nLoading volume 0...\")\n",
    "volume_0 = loader.load_volume_from_directory(str(volume_dirs[0]))\n",
    "\n",
    "print(\"Loading volume 1...\")\n",
    "volume_1 = loader.load_volume_from_directory(str(volume_dirs[1]))\n",
    "\n",
    "if volume_0 is None or volume_1 is None:\n",
    "    raise ValueError(\"Failed to load volumes\")\n",
    "\n",
    "print(f\"\\n‚úì Loaded volumes:\")\n",
    "print(f\"  Volume 0: {volume_0.shape} (Y, X, Z)\")\n",
    "print(f\"  Volume 1: {volume_1.shape}\")\n",
    "print(f\"\\n  Y = {volume_0.shape[0]} pixels (depth)\")\n",
    "print(f\"  X = {volume_0.shape[1]} pixels (lateral)\")\n",
    "print(f\"  Z = {volume_0.shape[2]} B-scans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply X-Z Translation to Volume 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply X-Z translation\n",
    "print(\"Applying X-Z translation to Volume 1...\")\n",
    "volume_1_xz_aligned = ndimage.shift(\n",
    "    volume_1,\n",
    "    shift=(0, offset_x, offset_z),  # (dy=0, dx, dz)\n",
    "    order=1,\n",
    "    mode='constant',\n",
    "    cval=0\n",
    ")\n",
    "\n",
    "print(f\"‚úì Applied X-Z alignment\")\n",
    "print(f\"  Translation: X={offset_x}, Z={offset_z}\")\n",
    "print(f\"  Volume 1 XZ-aligned shape: {volume_1_xz_aligned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implement 2D Phase Correlation for Y-offset\n",
    "\n",
    "This is the KEY innovation: using 2D phase correlation instead of 1D averaged profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_y_offset_2d_phase_correlation(bscan_ref, bscan_mov, max_shift=30):\n",
    "    \"\"\"\n",
    "    Calculate Y-axis offset using 2D phase correlation.\n",
    "    \n",
    "    This preserves spatial structure of vessels, unlike 1D averaging.\n",
    "    Based on successful X-Z alignment method from Phase 3.\n",
    "    \n",
    "    Args:\n",
    "        bscan_ref: Reference B-scan (Y, X)\n",
    "        bscan_mov: Moving B-scan (Y, X) - already XZ aligned\n",
    "        max_shift: Maximum Y-shift to search (pixels)\n",
    "    \n",
    "    Returns:\n",
    "        y_offset: Y-axis offset in pixels\n",
    "        confidence: Quality score based on peak strength\n",
    "    \"\"\"\n",
    "    # Normalize B-scans to zero mean, unit variance\n",
    "    ref_norm = (bscan_ref - bscan_ref.mean()) / (bscan_ref.std() + 1e-8)\n",
    "    mov_norm = (bscan_mov - bscan_mov.mean()) / (bscan_mov.std() + 1e-8)\n",
    "    \n",
    "    # 2D FFT phase correlation\n",
    "    f_ref = fft2(ref_norm)\n",
    "    f_mov = fft2(mov_norm)\n",
    "    \n",
    "    # Cross-power spectrum\n",
    "    cross_power = (f_ref * np.conj(f_mov)) / (np.abs(f_ref * np.conj(f_mov)) + 1e-8)\n",
    "    \n",
    "    # Inverse FFT to get correlation\n",
    "    correlation = np.fft.ifft2(cross_power).real\n",
    "    correlation = np.fft.fftshift(correlation)\n",
    "    \n",
    "    # Find peak in Y-direction (restrict search to max_shift)\n",
    "    center_y, center_x = np.array(correlation.shape) // 2\n",
    "    \n",
    "    # Search region: center_y ¬± max_shift, all X\n",
    "    y_start = max(0, center_y - max_shift)\n",
    "    y_end = min(correlation.shape[0], center_y + max_shift + 1)\n",
    "    \n",
    "    search_region = correlation[y_start:y_end, :]\n",
    "    \n",
    "    # Find peak position\n",
    "    peak_y, peak_x = np.unravel_index(np.argmax(search_region), search_region.shape)\n",
    "    \n",
    "    # Convert to offset from center\n",
    "    y_offset = (y_start + peak_y) - center_y\n",
    "    \n",
    "    # Confidence metric\n",
    "    peak_value = search_region[peak_y, peak_x]\n",
    "    \n",
    "    # Method 1: Peak-to-noise ratio\n",
    "    noise_level = search_region.std()\n",
    "    psnr_confidence = peak_value / (noise_level + 1e-8)\n",
    "    \n",
    "    # Method 2: Peak sharpness (ratio to second peak)\n",
    "    search_copy = search_region.copy()\n",
    "    search_copy[peak_y, peak_x] = -np.inf\n",
    "    second_peak = search_copy.max()\n",
    "    \n",
    "    if second_peak > 0:\n",
    "        peak_sharpness = peak_value / second_peak\n",
    "        sharpness_confidence = min(1.0, max(0.0, (peak_sharpness - 1.0) / 1.0))\n",
    "    else:\n",
    "        sharpness_confidence = 0.0\n",
    "    \n",
    "    # Combine confidences\n",
    "    confidence = 0.5 * min(1.0, psnr_confidence / 10.0) + 0.5 * sharpness_confidence\n",
    "    \n",
    "    return y_offset, confidence\n",
    "\n",
    "\n",
    "# For comparison: also implement the OLD 1D method\n",
    "def calculate_y_offset_1d_correlation(bscan_ref, bscan_mov, max_shift=30):\n",
    "    \"\"\"\n",
    "    OLD METHOD: 1D correlation on averaged profiles.\n",
    "    Kept for comparison only.\n",
    "    \"\"\"\n",
    "    # Normalize\n",
    "    ref_norm = (bscan_ref - bscan_ref.mean()) / (bscan_ref.std() + 1e-8)\n",
    "    mov_norm = (bscan_mov - bscan_mov.mean()) / (bscan_mov.std() + 1e-8)\n",
    "    \n",
    "    # Average along X (THIS IS THE PROBLEM!)\n",
    "    ref_profile = ref_norm.mean(axis=1)  # (Y,)\n",
    "    mov_profile = mov_norm.mean(axis=1)  # (Y,)\n",
    "    \n",
    "    # Normalize profiles\n",
    "    ref_profile = ref_profile - ref_profile.mean()\n",
    "    mov_profile = mov_profile - mov_profile.mean()\n",
    "    \n",
    "    # 1D correlation\n",
    "    correlation = signal.correlate(ref_profile, mov_profile, mode='same')\n",
    "    \n",
    "    # Find peak\n",
    "    center = len(correlation) // 2\n",
    "    search_start = max(0, center - max_shift)\n",
    "    search_end = min(len(correlation), center + max_shift + 1)\n",
    "    \n",
    "    search_region = correlation[search_start:search_end]\n",
    "    peak_idx = np.argmax(search_region)\n",
    "    peak_pos = search_start + peak_idx\n",
    "    \n",
    "    y_offset = peak_pos - center\n",
    "    \n",
    "    # Confidence\n",
    "    ref_energy = np.sum(ref_profile ** 2)\n",
    "    mov_energy = np.sum(mov_profile ** 2)\n",
    "    \n",
    "    if ref_energy > 0 and mov_energy > 0:\n",
    "        ncc_peak = correlation[peak_pos] / np.sqrt(ref_energy * mov_energy)\n",
    "        confidence = max(0.0, min(1.0, ncc_peak))\n",
    "    else:\n",
    "        confidence = 0.0\n",
    "    \n",
    "    return y_offset, confidence\n",
    "\n",
    "print(\"‚úì 2D Phase Correlation functions defined\")\n",
    "print(\"‚úì 1D Correlation function (for comparison) defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test on Sample B-scans\n",
    "\n",
    "Test both methods on 10 B-scans to compare performance before running on all 360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 10 evenly distributed B-scans for testing\n",
    "num_bscans = volume_0.shape[2]\n",
    "test_indices = np.linspace(0, num_bscans-1, 10, dtype=int)\n",
    "\n",
    "print(f\"Testing on {len(test_indices)} B-scans: {test_indices.tolist()}\")\n",
    "print(f\"\\nComparing 2D Phase Correlation vs 1D Correlation...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_2d = []\n",
    "results_1d = []\n",
    "\n",
    "for i, z in enumerate(test_indices):\n",
    "    # Extract B-scans\n",
    "    bscan_ref = volume_0[:, :, z]\n",
    "    bscan_mov = volume_1_xz_aligned[:, :, z]\n",
    "    \n",
    "    # Method 1: 2D Phase Correlation\n",
    "    offset_2d, conf_2d = calculate_y_offset_2d_phase_correlation(\n",
    "        bscan_ref, bscan_mov, max_shift=30\n",
    "    )\n",
    "    \n",
    "    # Method 2: 1D Correlation (old method)\n",
    "    offset_1d, conf_1d = calculate_y_offset_1d_correlation(\n",
    "        bscan_ref, bscan_mov, max_shift=30\n",
    "    )\n",
    "    \n",
    "    results_2d.append({'z': z, 'offset': offset_2d, 'confidence': conf_2d})\n",
    "    results_1d.append({'z': z, 'offset': offset_1d, 'confidence': conf_1d})\n",
    "    \n",
    "    print(f\"B-scan Z={z:3d}:\")\n",
    "    print(f\"  2D Phase Corr: offset={offset_2d:+5.1f} px, conf={conf_2d:.2%}\")\n",
    "    print(f\"  1D Corr (old): offset={offset_1d:+5.1f} px, conf={conf_1d:.2%}\")\n",
    "    print(f\"  Difference:    {abs(offset_2d - offset_1d):5.1f} px\")\n",
    "    print()\n",
    "\n",
    "# Statistics\n",
    "offsets_2d = np.array([r['offset'] for r in results_2d])\n",
    "confs_2d = np.array([r['confidence'] for r in results_2d])\n",
    "\n",
    "offsets_1d = np.array([r['offset'] for r in results_1d])\n",
    "confs_1d = np.array([r['confidence'] for r in results_1d])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä COMPARISON STATISTICS\\n\")\n",
    "print(f\"2D Phase Correlation:\")\n",
    "print(f\"  Mean offset: {offsets_2d.mean():+.2f} ¬± {offsets_2d.std():.2f} px\")\n",
    "print(f\"  Mean confidence: {confs_2d.mean():.2%}\")\n",
    "print(f\"  Range: [{offsets_2d.min():.1f}, {offsets_2d.max():.1f}]\")\n",
    "\n",
    "print(f\"\\n1D Correlation (old):\")\n",
    "print(f\"  Mean offset: {offsets_1d.mean():+.2f} ¬± {offsets_1d.std():.2f} px\")\n",
    "print(f\"  Mean confidence: {confs_1d.mean():.2%}\")\n",
    "print(f\"  Range: [{offsets_1d.min():.1f}, {offsets_1d.max():.1f}]\")\n",
    "\n",
    "print(f\"\\nüí° Key Metrics:\")\n",
    "print(f\"  Offset std reduction: {100*(1 - offsets_2d.std()/offsets_1d.std()):.1f}%\")\n",
    "print(f\"  Confidence improvement: {100*(confs_2d.mean() - confs_1d.mean())/confs_1d.mean():.1f}%\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison for 3 sample B-scans\n",
    "sample_indices = [test_indices[2], test_indices[5], test_indices[8]]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 12))\n",
    "\n",
    "for row, z in enumerate(sample_indices):\n",
    "    # Get B-scans\n",
    "    bscan_ref = volume_0[:, :, z]\n",
    "    bscan_mov = volume_1_xz_aligned[:, :, z]\n",
    "    \n",
    "    # Get offsets\n",
    "    idx = np.where(test_indices == z)[0][0]\n",
    "    offset_2d = results_2d[idx]['offset']\n",
    "    offset_1d = results_1d[idx]['offset']\n",
    "    conf_2d = results_2d[idx]['confidence']\n",
    "    conf_1d = results_1d[idx]['confidence']\n",
    "    \n",
    "    # Apply shifts\n",
    "    bscan_aligned_2d = ndimage.shift(bscan_mov, shift=(offset_2d, 0), order=1, mode='constant', cval=0)\n",
    "    bscan_aligned_1d = ndimage.shift(bscan_mov, shift=(offset_1d, 0), order=1, mode='constant', cval=0)\n",
    "    \n",
    "    # Column 1: Reference\n",
    "    axes[row, 0].imshow(bscan_ref, cmap='gray', aspect='auto')\n",
    "    axes[row, 0].set_title(f'Vol 0 (ref)\\nZ={z}', fontweight='bold')\n",
    "    axes[row, 0].set_ylabel('Y (depth)')\n",
    "    \n",
    "    # Column 2: Before alignment\n",
    "    axes[row, 1].imshow(bscan_mov, cmap='gray', aspect='auto')\n",
    "    axes[row, 1].set_title('Vol 1 (XZ only)', fontweight='bold')\n",
    "    \n",
    "    # Column 3: After 2D phase corr\n",
    "    diff_2d = np.abs(bscan_ref.astype(float) - bscan_aligned_2d.astype(float)).mean()\n",
    "    axes[row, 2].imshow(bscan_aligned_2d, cmap='gray', aspect='auto')\n",
    "    axes[row, 2].set_title(f'2D Phase Corr\\nY={offset_2d:+.1f}px, conf={conf_2d:.1%}\\nDiff={diff_2d:.2f}',\n",
    "                          fontweight='bold')\n",
    "    \n",
    "    # Column 4: After 1D corr\n",
    "    diff_1d = np.abs(bscan_ref.astype(float) - bscan_aligned_1d.astype(float)).mean()\n",
    "    axes[row, 3].imshow(bscan_aligned_1d, cmap='gray', aspect='auto')\n",
    "    axes[row, 3].set_title(f'1D Corr (old)\\nY={offset_1d:+.1f}px, conf={conf_1d:.1%}\\nDiff={diff_1d:.2f}',\n",
    "                          fontweight='bold')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('X (lateral)')\n",
    "\n",
    "plt.suptitle('Method Comparison: 2D Phase Correlation vs 1D Correlation', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Look for:\")\n",
    "print(\"  - Better alignment (clearer tissue boundaries)\")\n",
    "print(\"  - Lower difference values\")\n",
    "print(\"  - Higher confidence scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Decision: Apply to All B-scans?\n",
    "\n",
    "Based on test results, decide whether to use 2D phase correlation for all 360 B-scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically decide based on metrics\n",
    "confidence_improvement = (confs_2d.mean() - confs_1d.mean()) / confs_1d.mean()\n",
    "offset_std_reduction = (offsets_1d.std() - offsets_2d.std()) / offsets_1d.std()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DECISION CRITERIA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n1. Confidence improvement: {100*confidence_improvement:+.1f}%\")\n",
    "print(f\"   ‚úÖ Good if > +10%\" if confidence_improvement > 0.1 else \"   ‚ö†Ô∏è Marginal if < +10%\")\n",
    "\n",
    "print(f\"\\n2. Offset std reduction: {100*offset_std_reduction:+.1f}%\")\n",
    "print(f\"   ‚úÖ Good if > +20%\" if offset_std_reduction > 0.2 else \"   ‚ö†Ô∏è Marginal if < +20%\")\n",
    "\n",
    "print(f\"\\n3. Mean confidence (2D): {100*confs_2d.mean():.1f}%\")\n",
    "print(f\"   ‚úÖ Good if > 60%\" if confs_2d.mean() > 0.6 else \"   ‚ö†Ô∏è Marginal if < 60%\")\n",
    "\n",
    "# Make decision\n",
    "use_2d_method = (confidence_improvement > 0.1 and offset_std_reduction > 0.2) or confs_2d.mean() > 0.6\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if use_2d_method:\n",
    "    print(\"‚úÖ DECISION: Use 2D Phase Correlation for all 360 B-scans\")\n",
    "    print(\"   Metrics show clear improvement over 1D method.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è DECISION: Results unclear - need manual review\")\n",
    "    print(\"   Consider trying alternative methods or checking if Y-alignment is needed.\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ask user to confirm\n",
    "print(\"\\nüëÜ Please review the visualizations and statistics above.\")\n",
    "print(\"   Then run the next cell to apply to all B-scans.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Apply to All 360 B-scans (if successful)\n",
    "\n",
    "Run this cell only if the test results look promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Y-offset for ALL B-scans using 2D phase correlation\n",
    "num_bscans = volume_0.shape[2]\n",
    "y_offsets_2d = np.zeros(num_bscans, dtype=np.float32)\n",
    "confidences_2d = np.zeros(num_bscans, dtype=np.float32)\n",
    "\n",
    "print(f\"Calculating Y-offset for each of {num_bscans} B-scans using 2D Phase Correlation...\")\n",
    "print(\"This may take 2-3 minutes...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for z in range(num_bscans):\n",
    "    if z % 50 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        eta = (elapsed / (z+1)) * (num_bscans - z - 1) if z > 0 else 0\n",
    "        print(f\"  Processing B-scan {z}/{num_bscans}... (ETA: {eta:.0f}s)\")\n",
    "    \n",
    "    # Extract B-scans\n",
    "    bscan_ref = volume_0[:, :, z]\n",
    "    bscan_mov = volume_1_xz_aligned[:, :, z]\n",
    "    \n",
    "    # Calculate Y-offset with 2D phase correlation\n",
    "    y_offset, confidence = calculate_y_offset_2d_phase_correlation(\n",
    "        bscan_ref, bscan_mov, max_shift=30\n",
    "    )\n",
    "    \n",
    "    y_offsets_2d[z] = y_offset\n",
    "    confidences_2d[z] = confidence\n",
    "\n",
    "elapsed_total = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úì Calculated {len(y_offsets_2d)} per-B-scan Y-offsets in {elapsed_total:.1f}s\")\n",
    "print(f\"\\nüìä Y-offset statistics (2D Phase Correlation):\")\n",
    "print(f\"  Mean offset: {y_offsets_2d.mean():.2f} ¬± {y_offsets_2d.std():.2f} pixels\")\n",
    "print(f\"  Median offset: {np.median(y_offsets_2d):.2f} pixels\")\n",
    "print(f\"  Range: [{y_offsets_2d.min():.2f}, {y_offsets_2d.max():.2f}] pixels\")\n",
    "print(f\"\\nüìà Confidence statistics:\")\n",
    "print(f\"  Mean confidence: {confidences_2d.mean():.2%}\")\n",
    "print(f\"  Median confidence: {np.median(confidences_2d):.2%}\")\n",
    "print(f\"  Range: [{confidences_2d.min():.2%}, {confidences_2d.max():.2%}]\")\n",
    "\n",
    "# Count high confidence B-scans\n",
    "high_conf = (confidences_2d > 0.6).sum()\n",
    "print(f\"  High confidence B-scans (>60%): {high_conf}/{num_bscans} ({100*high_conf/num_bscans:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Per-B-scan Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Y-offsets vs B-scan index\n",
    "axes[0, 0].plot(y_offsets_2d, linewidth=2, color='blue', label='2D Phase Corr')\n",
    "axes[0, 0].axhline(y_offsets_2d.mean(), color='red', linestyle='--', \n",
    "                  label=f'Mean: {y_offsets_2d.mean():.2f} px')\n",
    "axes[0, 0].axhline(np.median(y_offsets_2d), color='green', linestyle='--', \n",
    "                  label=f'Median: {np.median(y_offsets_2d):.2f} px')\n",
    "axes[0, 0].set_xlabel('B-scan index (Z)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Y-offset (depth, pixels)', fontsize=12)\n",
    "axes[0, 0].set_title('Per-B-scan Y-offsets (2D Phase Correlation)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Confidence vs B-scan index\n",
    "axes[0, 1].plot(confidences_2d, linewidth=2, color='orange')\n",
    "axes[0, 1].axhline(0.6, color='red', linestyle='--', alpha=0.5, label='60% threshold')\n",
    "axes[0, 1].axhline(confidences_2d.mean(), color='blue', linestyle='--', \n",
    "                  label=f'Mean: {confidences_2d.mean():.2%}')\n",
    "axes[0, 1].set_xlabel('B-scan index (Z)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Confidence', fontsize=12)\n",
    "axes[0, 1].set_title('Alignment Confidence per B-scan', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Histogram of Y-offsets\n",
    "axes[1, 0].hist(y_offsets_2d, bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].axvline(y_offsets_2d.mean(), color='red', linestyle='--', linewidth=2, \n",
    "                  label=f'Mean: {y_offsets_2d.mean():.2f}')\n",
    "axes[1, 0].axvline(np.median(y_offsets_2d), color='green', linestyle='--', linewidth=2, \n",
    "                  label=f'Median: {np.median(y_offsets_2d):.2f}')\n",
    "axes[1, 0].set_xlabel('Y-offset (pixels)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Count', fontsize=12)\n",
    "axes[1, 0].set_title('Distribution of Y-offsets', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Y-offset vs Confidence scatter\n",
    "scatter = axes[1, 1].scatter(y_offsets_2d, confidences_2d, c=confidences_2d, \n",
    "                            cmap='viridis', s=20, alpha=0.6)\n",
    "axes[1, 1].axhline(0.6, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Y-offset (pixels)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Confidence', fontsize=12)\n",
    "axes[1, 1].set_title('Offset vs Confidence', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='Confidence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key observations:\")\n",
    "print(\"  - Smooth offsets across Z indicate stable alignment\")\n",
    "print(\"  - High confidence = strong 2D correlation peak\")\n",
    "print(\"  - Large jumps may indicate motion or different structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Apply Per-B-scan Y-alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_per_bscan_y_alignment(volume, y_offsets):\n",
    "    \"\"\"\n",
    "    Apply per-B-scan Y-shifts to volume.\n",
    "    \n",
    "    Args:\n",
    "        volume: Volume to align (Y, X, Z)\n",
    "        y_offsets: Y-offset per B-scan (Z,)\n",
    "    \n",
    "    Returns:\n",
    "        aligned_volume: Y-aligned volume (Y, X, Z)\n",
    "    \"\"\"\n",
    "    Y, X, Z = volume.shape\n",
    "    aligned_volume = np.zeros_like(volume)\n",
    "    \n",
    "    print(f\"Applying per-B-scan Y-shifts...\")\n",
    "    \n",
    "    for z in range(Z):\n",
    "        if z % 50 == 0:\n",
    "            print(f\"  B-scan {z}/{Z}...\")\n",
    "        \n",
    "        # Shift this B-scan along Y-axis\n",
    "        bscan = volume[:, :, z]\n",
    "        bscan_shifted = ndimage.shift(bscan, shift=(y_offsets[z], 0), \n",
    "                                     order=1, mode='constant', cval=0)\n",
    "        aligned_volume[:, :, z] = bscan_shifted\n",
    "    \n",
    "    return aligned_volume\n",
    "\n",
    "# Apply Y-alignment\n",
    "print(\"\\nApplying per-B-scan Y-alignment to Volume 1...\")\n",
    "volume_1_fully_aligned = apply_per_bscan_y_alignment(volume_1_xz_aligned, y_offsets_2d)\n",
    "\n",
    "print(f\"\\n‚úì Volume 1 fully aligned (X, Y, Z)\")\n",
    "print(f\"  Shape: {volume_1_fully_aligned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate Alignment Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate alignment quality\n",
    "print(\"Calculating alignment improvement...\")\n",
    "\n",
    "diff_before_all = np.abs(volume_0.astype(float) - volume_1_xz_aligned.astype(float))\n",
    "diff_after_all = np.abs(volume_0.astype(float) - volume_1_fully_aligned.astype(float))\n",
    "\n",
    "improvement = 100 * (1 - diff_after_all.mean() / diff_before_all.mean())\n",
    "\n",
    "print(\"\\nüìä Overall Alignment Quality:\")\n",
    "print(f\"  Before Y-alignment: {diff_before_all.mean():.2f} ¬± {diff_before_all.std():.2f}\")\n",
    "print(f\"  After Y-alignment:  {diff_after_all.mean():.2f} ¬± {diff_after_all.std():.2f}\")\n",
    "print(f\"  Improvement: {improvement:.2f}%\", end=\"\")\n",
    "\n",
    "if improvement > 10:\n",
    "    print(\" ‚úÖ EXCELLENT!\")\n",
    "elif improvement > 5:\n",
    "    print(\" ‚úÖ GOOD\")\n",
    "elif improvement > 1:\n",
    "    print(\" ‚ö†Ô∏è MODERATE\")\n",
    "else:\n",
    "    print(\" ‚ùå MINIMAL - Y-alignment may not be needed\")\n",
    "\n",
    "print(f\"\\nüìä Comparison with old 1D method:\")\n",
    "print(f\"  Old 1D method improvement: 0.1%\")\n",
    "print(f\"  New 2D method improvement: {improvement:.2f}%\")\n",
    "print(f\"  Relative improvement: {improvement/0.1:.1f}x better!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Visualize Alignment Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare B-scans before and after Y-alignment\n",
    "z_samples = [num_bscans // 4, num_bscans // 2, 3 * num_bscans // 4]\n",
    "\n",
    "fig, axes = plt.subplots(len(z_samples), 4, figsize=(20, 5*len(z_samples)))\n",
    "\n",
    "for i, z in enumerate(z_samples):\n",
    "    # Column 1: Reference B-scan\n",
    "    axes[i, 0].imshow(volume_0[:, :, z], cmap='gray', aspect='auto')\n",
    "    axes[i, 0].set_title(f'Vol 0 (ref) - Z={z}', fontweight='bold')\n",
    "    axes[i, 0].set_ylabel('Y (depth)')\n",
    "    axes[i, 0].set_xlabel('X (lateral)')\n",
    "    \n",
    "    # Column 2: Vol 1 before Y-alignment (XZ only)\n",
    "    axes[i, 1].imshow(volume_1_xz_aligned[:, :, z], cmap='gray', aspect='auto')\n",
    "    axes[i, 1].set_title(f'Vol 1 (XZ aligned) - Z={z}', fontweight='bold')\n",
    "    axes[i, 1].set_xlabel('X (lateral)')\n",
    "    \n",
    "    # Column 3: Vol 1 after full XYZ alignment\n",
    "    axes[i, 2].imshow(volume_1_fully_aligned[:, :, z], cmap='gray', aspect='auto')\n",
    "    axes[i, 2].set_title(f'Vol 1 (XYZ aligned) - Z={z}\\nY-shift: {y_offsets_2d[z]:.2f} px (conf={confidences_2d[z]:.1%})', \n",
    "                        fontweight='bold')\n",
    "    axes[i, 2].set_xlabel('X (lateral)')\n",
    "    \n",
    "    # Column 4: Difference map\n",
    "    diff_before = np.abs(volume_0[:, :, z].astype(float) - volume_1_xz_aligned[:, :, z].astype(float))\n",
    "    diff_after = np.abs(volume_0[:, :, z].astype(float) - volume_1_fully_aligned[:, :, z].astype(float))\n",
    "    \n",
    "    diff_reduction = diff_before - diff_after\n",
    "    im = axes[i, 3].imshow(diff_reduction, cmap='RdYlGn', aspect='auto', vmin=-20, vmax=diff_reduction.max())\n",
    "    axes[i, 3].set_title(f'Improvement (pos=better)\\nMean: {diff_reduction.mean():.2f}', fontweight='bold')\n",
    "    axes[i, 3].set_xlabel('X (lateral)')\n",
    "    plt.colorbar(im, ax=axes[i, 3], label='Difference reduction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Green areas = improvement, red areas = worse (should be mostly green!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aligned volume\n",
    "print(\"Saving results...\")\n",
    "np.save(data_dir / 'volume_1_fully_aligned_2d.npy', volume_1_fully_aligned)\n",
    "\n",
    "# Save Y-alignment parameters\n",
    "y_alignment_params = {\n",
    "    'method': 'per_bscan_2d_phase_correlation',\n",
    "    'y_offsets': y_offsets_2d.tolist(),\n",
    "    'confidences': confidences_2d.tolist(),\n",
    "    'mean_offset': float(y_offsets_2d.mean()),\n",
    "    'median_offset': float(np.median(y_offsets_2d)),\n",
    "    'offset_std': float(y_offsets_2d.std()),\n",
    "    'mean_confidence': float(confidences_2d.mean()),\n",
    "    'median_confidence': float(np.median(confidences_2d)),\n",
    "    'high_confidence_count': int((confidences_2d > 0.6).sum()),\n",
    "    'improvement_percent': float(improvement),\n",
    "    'max_shift': 30\n",
    "}\n",
    "\n",
    "np.save(data_dir / 'y_alignment_params_2d.npy', y_alignment_params, allow_pickle=True)\n",
    "\n",
    "# Save complete 3D registration\n",
    "registration_3d = {\n",
    "    # X-Z alignment (global)\n",
    "    'translation_x': int(offset_x),\n",
    "    'translation_z': int(offset_z),\n",
    "    'xz_method': xy_params.get('best_method', 'phase_correlation'),\n",
    "    'xz_confidence': float(xy_params['confidence']),\n",
    "    'xz_improvement': float(xy_params['improvement_percent']),\n",
    "    \n",
    "    # Y alignment (per-B-scan with 2D phase correlation)\n",
    "    'y_method': 'per_bscan_2d_phase_correlation',\n",
    "    'y_offsets_per_bscan': y_offsets_2d.tolist(),\n",
    "    'y_confidences_per_bscan': confidences_2d.tolist(),\n",
    "    'y_mean_offset': float(y_offsets_2d.mean()),\n",
    "    'y_median_offset': float(np.median(y_offsets_2d)),\n",
    "    'y_mean_confidence': float(confidences_2d.mean()),\n",
    "    'y_improvement': float(improvement),\n",
    "    \n",
    "    # Transform summary\n",
    "    'transform_3d': {\n",
    "        'x_offset': int(offset_x),\n",
    "        'z_offset': int(offset_z),\n",
    "        'y_offsets': y_offsets_2d.tolist()  # Per-B-scan\n",
    "    }\n",
    "}\n",
    "\n",
    "np.save(data_dir / 'registration_3d_params_2d.npy', registration_3d, allow_pickle=True)\n",
    "\n",
    "print(\"\\n‚úì Saved:\")\n",
    "print(\"  - volume_1_fully_aligned_2d.npy\")\n",
    "print(\"  - y_alignment_params_2d.npy\")\n",
    "print(\"  - registration_3d_params_2d.npy\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL 3D REGISTRATION SUMMARY (2D Phase Correlation)\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüìç X-Z Alignment (Global):\")\n",
    "print(f\"  Method: {xy_params.get('best_method', 'phase_correlation')}\")\n",
    "print(f\"  X offset: {offset_x} px\")\n",
    "print(f\"  Z offset: {offset_z} px\")\n",
    "print(f\"  Confidence: {xy_params['confidence']:.2f}\")\n",
    "print(f\"  Improvement: {xy_params['improvement_percent']:.1f}%\")\n",
    "print(f\"\\nüìè Y-axis Alignment (Per-B-scan 2D Phase Correlation):\")\n",
    "print(f\"  Method: 2D phase correlation (preserves spatial structure)\")\n",
    "print(f\"  Mean Y-offset: {y_offsets_2d.mean():.2f} ¬± {y_offsets_2d.std():.2f} px\")\n",
    "print(f\"  Median Y-offset: {np.median(y_offsets_2d):.2f} px\")\n",
    "print(f\"  Range: [{y_offsets_2d.min():.2f}, {y_offsets_2d.max():.2f}] px\")\n",
    "print(f\"  Mean confidence: {confidences_2d.mean():.2%}\")\n",
    "print(f\"  High confidence B-scans: {(confidences_2d>0.6).sum()}/{num_bscans}\")\n",
    "print(f\"  Improvement: {improvement:.2f}%\")\n",
    "print(f\"\\nüéØ Comparison with old 1D method:\")\n",
    "print(f\"  Old improvement: 0.1%\")\n",
    "print(f\"  New improvement: {improvement:.2f}%\")\n",
    "print(f\"  Relative gain: {improvement/0.1:.1f}x better!\")\n",
    "print(f\"\\n‚úÖ Full 3D registration complete!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implemented **2D phase correlation** for Y-axis alignment:\n",
    "\n",
    "### Key innovation:\n",
    "- ‚ùå Old: 1D correlation on averaged X profiles (lost spatial info)\n",
    "- ‚úÖ New: 2D phase correlation on full B-scan images (preserves vessel structure)\n",
    "\n",
    "### Method inspiration:\n",
    "- Adapted from Phase 3 X-Z registration (15.8% improvement)\n",
    "- Uses full 2D FFT-based phase correlation\n",
    "- Restricted search range (max_shift=30) for efficiency\n",
    "\n",
    "### Results:\n",
    "- See final summary above for detailed metrics\n",
    "- If improvement > 5%: Success! ‚úÖ\n",
    "- If improvement < 5%: May need alternative approach or Y-alignment not needed\n",
    "\n",
    "### Next steps:\n",
    "- Use `06_visualize_results.ipynb` to create 3D merged volume\n",
    "- Compare with old 1D method results\n",
    "- If needed: Try Method 2 (weighted 1D) or Method 3 (global median)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
